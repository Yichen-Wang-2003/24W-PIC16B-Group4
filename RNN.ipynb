{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ningsam/anaconda3/envs/YichenWang/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/var/folders/3w/bkk9z93s1294lzphg00_yxnw0000gn/T/ipykernel_96929/4243316776.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.read_csv(\"target.csv\")\n",
    "ds = pd.read_csv(\"/Users/ningsam/Desktop/Winter_2024/PIC16B/df_2023_h1_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>250.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>423.693802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>24.340258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>373.700256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>404.687393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>425.332275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>442.607903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>476.690002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Adj Close\n",
       "count  250.000000\n",
       "mean   423.693802\n",
       "std     24.340258\n",
       "min    373.700256\n",
       "25%    404.687393\n",
       "50%    425.332275\n",
       "75%    442.607903\n",
       "max    476.690002"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in ds[\"Date\"].unique():\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['[QUOTE_UNIXTIME]', '[EXPIRE_UNIX]', '[EXPIRE_DATE]', '[STRIKE]',\n",
       "       '[UNDERLYING_LAST]', '[C_DELTA]', '[C_GAMMA]', '[C_VEGA]', '[C_THETA]',\n",
       "       '[C_RHO]', '[C_IV]', '[C_VOLUME]', '[C_BID]', '[C_ASK]', '[P_DELTA]',\n",
       "       '[P_GAMMA]', '[P_VEGA]', '[P_THETA]', '[P_RHO]', '[P_IV]', '[P_VOLUME]',\n",
       "       '[P_BID]', '[P_ASK]'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename ds's \"[EXPIRE_DATE]\" to \"Date\" \n",
    "# NOTE: Here the date refers to the expiration date of the option\n",
    "ds.rename(columns={\"[EXPIRE_DATE]\": \"Date\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort both df per Date col\n",
    "ds = ds.sort_values(by=\"Date\").reset_index(drop=True)\n",
    "target = target.sort_values(by=\"Date\").reset_index(drop=True)\n",
    "# Remove the Unnamed column\n",
    "ds = ds.loc[:, ~ds.columns.str.contains('^Unnamed')]  \n",
    "ds['Date'] = pd.to_datetime(ds['Date'])\n",
    "target['Date'] = pd.to_datetime(target['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_new = pd.merge(ds, target, on='Date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>[QUOTE_UNIXTIME]</th>\n",
       "      <th>[EXPIRE_UNIX]</th>\n",
       "      <th>Date</th>\n",
       "      <th>[STRIKE]</th>\n",
       "      <th>[UNDERLYING_LAST]</th>\n",
       "      <th>[C_DELTA]</th>\n",
       "      <th>[C_GAMMA]</th>\n",
       "      <th>[C_VEGA]</th>\n",
       "      <th>[C_THETA]</th>\n",
       "      <th>[C_RHO]</th>\n",
       "      <th>...</th>\n",
       "      <th>[P_DELTA]</th>\n",
       "      <th>[P_GAMMA]</th>\n",
       "      <th>[P_VEGA]</th>\n",
       "      <th>[P_THETA]</th>\n",
       "      <th>[P_RHO]</th>\n",
       "      <th>[P_IV]</th>\n",
       "      <th>[P_VOLUME]</th>\n",
       "      <th>[P_BID]</th>\n",
       "      <th>[P_ASK]</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.691600</td>\n",
       "      <td>-1.531564</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>-1.054517</td>\n",
       "      <td>-2.406592</td>\n",
       "      <td>1.054125</td>\n",
       "      <td>-0.052714</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>-0.391189</td>\n",
       "      <td>-0.307878</td>\n",
       "      <td>...</td>\n",
       "      <td>1.120791</td>\n",
       "      <td>-0.013192</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>0.086874</td>\n",
       "      <td>0.592295</td>\n",
       "      <td>3.380989</td>\n",
       "      <td>-0.100406</td>\n",
       "      <td>-0.563368</td>\n",
       "      <td>-0.566211</td>\n",
       "      <td>375.118713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.691600</td>\n",
       "      <td>-1.531564</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>0.141988</td>\n",
       "      <td>-2.406592</td>\n",
       "      <td>-1.302375</td>\n",
       "      <td>-0.388302</td>\n",
       "      <td>-0.000293</td>\n",
       "      <td>0.804031</td>\n",
       "      <td>-0.308329</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331602</td>\n",
       "      <td>-0.013434</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>0.090668</td>\n",
       "      <td>0.592878</td>\n",
       "      <td>-1.037447</td>\n",
       "      <td>-0.099559</td>\n",
       "      <td>-0.005324</td>\n",
       "      <td>0.011661</td>\n",
       "      <td>375.118713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.691600</td>\n",
       "      <td>-1.531564</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>0.130141</td>\n",
       "      <td>-2.406592</td>\n",
       "      <td>-1.302766</td>\n",
       "      <td>-0.385148</td>\n",
       "      <td>-0.000318</td>\n",
       "      <td>0.809161</td>\n",
       "      <td>-0.308903</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331602</td>\n",
       "      <td>-0.013434</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>0.090668</td>\n",
       "      <td>0.592878</td>\n",
       "      <td>-1.037447</td>\n",
       "      <td>-0.099728</td>\n",
       "      <td>-0.022073</td>\n",
       "      <td>-0.007267</td>\n",
       "      <td>375.118713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.691600</td>\n",
       "      <td>-1.531564</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>0.118294</td>\n",
       "      <td>-2.406592</td>\n",
       "      <td>-1.304380</td>\n",
       "      <td>-0.387672</td>\n",
       "      <td>-0.000283</td>\n",
       "      <td>0.800571</td>\n",
       "      <td>-0.308799</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331602</td>\n",
       "      <td>-0.013434</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>0.090668</td>\n",
       "      <td>0.592878</td>\n",
       "      <td>-1.037447</td>\n",
       "      <td>-0.090071</td>\n",
       "      <td>-0.043390</td>\n",
       "      <td>-0.026195</td>\n",
       "      <td>375.118713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.691600</td>\n",
       "      <td>-1.531564</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>0.106448</td>\n",
       "      <td>-2.406592</td>\n",
       "      <td>-1.303866</td>\n",
       "      <td>-0.385148</td>\n",
       "      <td>-0.000300</td>\n",
       "      <td>0.809758</td>\n",
       "      <td>-0.308329</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331602</td>\n",
       "      <td>-0.013434</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>0.090668</td>\n",
       "      <td>0.592878</td>\n",
       "      <td>-1.037447</td>\n",
       "      <td>-0.098712</td>\n",
       "      <td>-0.060139</td>\n",
       "      <td>-0.045123</td>\n",
       "      <td>375.118713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331604</th>\n",
       "      <td>-0.470746</td>\n",
       "      <td>2.332822</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>-1.350682</td>\n",
       "      <td>-0.792335</td>\n",
       "      <td>0.908009</td>\n",
       "      <td>-0.323330</td>\n",
       "      <td>0.028591</td>\n",
       "      <td>0.327876</td>\n",
       "      <td>1.567932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.940700</td>\n",
       "      <td>-0.011274</td>\n",
       "      <td>0.027561</td>\n",
       "      <td>0.073490</td>\n",
       "      <td>-0.464073</td>\n",
       "      <td>0.053898</td>\n",
       "      <td>-0.100406</td>\n",
       "      <td>-0.487046</td>\n",
       "      <td>-0.488228</td>\n",
       "      <td>475.309998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331605</th>\n",
       "      <td>-0.470746</td>\n",
       "      <td>2.332822</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>-1.291449</td>\n",
       "      <td>-0.792335</td>\n",
       "      <td>0.893192</td>\n",
       "      <td>-0.316391</td>\n",
       "      <td>0.030232</td>\n",
       "      <td>0.305088</td>\n",
       "      <td>1.583821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.922980</td>\n",
       "      <td>-0.011194</td>\n",
       "      <td>0.029314</td>\n",
       "      <td>0.072979</td>\n",
       "      <td>-0.552965</td>\n",
       "      <td>0.038197</td>\n",
       "      <td>-0.099728</td>\n",
       "      <td>-0.480575</td>\n",
       "      <td>-0.481792</td>\n",
       "      <td>475.309998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331606</th>\n",
       "      <td>-0.470746</td>\n",
       "      <td>2.332822</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>-1.232216</td>\n",
       "      <td>-0.792335</td>\n",
       "      <td>0.878326</td>\n",
       "      <td>-0.310083</td>\n",
       "      <td>0.031854</td>\n",
       "      <td>0.294231</td>\n",
       "      <td>1.598922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.905580</td>\n",
       "      <td>-0.010968</td>\n",
       "      <td>0.031117</td>\n",
       "      <td>0.071872</td>\n",
       "      <td>-0.645241</td>\n",
       "      <td>0.018808</td>\n",
       "      <td>-0.100067</td>\n",
       "      <td>-0.473152</td>\n",
       "      <td>-0.475167</td>\n",
       "      <td>475.309998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331607</th>\n",
       "      <td>-0.470746</td>\n",
       "      <td>2.332822</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>-1.113750</td>\n",
       "      <td>-0.792335</td>\n",
       "      <td>0.843019</td>\n",
       "      <td>-0.294943</td>\n",
       "      <td>0.035285</td>\n",
       "      <td>0.256172</td>\n",
       "      <td>1.624471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.868226</td>\n",
       "      <td>-0.010533</td>\n",
       "      <td>0.034955</td>\n",
       "      <td>0.070434</td>\n",
       "      <td>-0.859345</td>\n",
       "      <td>-0.016721</td>\n",
       "      <td>-0.100236</td>\n",
       "      <td>-0.462113</td>\n",
       "      <td>-0.453968</td>\n",
       "      <td>475.309998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331608</th>\n",
       "      <td>1.782160</td>\n",
       "      <td>2.332822</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>1.551731</td>\n",
       "      <td>1.410238</td>\n",
       "      <td>-1.271836</td>\n",
       "      <td>-0.351716</td>\n",
       "      <td>0.005918</td>\n",
       "      <td>0.815007</td>\n",
       "      <td>-0.276616</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.245557</td>\n",
       "      <td>-0.007327</td>\n",
       "      <td>0.009872</td>\n",
       "      <td>0.086136</td>\n",
       "      <td>-0.161231</td>\n",
       "      <td>-0.182059</td>\n",
       "      <td>-0.100406</td>\n",
       "      <td>1.539002</td>\n",
       "      <td>1.591013</td>\n",
       "      <td>475.309998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>331609 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        [QUOTE_UNIXTIME]  [EXPIRE_UNIX]       Date  [STRIKE]  \\\n",
       "0              -1.691600      -1.531564 2023-01-03 -1.054517   \n",
       "1              -1.691600      -1.531564 2023-01-03  0.141988   \n",
       "2              -1.691600      -1.531564 2023-01-03  0.130141   \n",
       "3              -1.691600      -1.531564 2023-01-03  0.118294   \n",
       "4              -1.691600      -1.531564 2023-01-03  0.106448   \n",
       "...                  ...            ...        ...       ...   \n",
       "331604         -0.470746       2.332822 2023-12-29 -1.350682   \n",
       "331605         -0.470746       2.332822 2023-12-29 -1.291449   \n",
       "331606         -0.470746       2.332822 2023-12-29 -1.232216   \n",
       "331607         -0.470746       2.332822 2023-12-29 -1.113750   \n",
       "331608          1.782160       2.332822 2023-12-29  1.551731   \n",
       "\n",
       "        [UNDERLYING_LAST]  [C_DELTA]  [C_GAMMA]  [C_VEGA]  [C_THETA]  \\\n",
       "0               -2.406592   1.054125  -0.052714  0.000146  -0.391189   \n",
       "1               -2.406592  -1.302375  -0.388302 -0.000293   0.804031   \n",
       "2               -2.406592  -1.302766  -0.385148 -0.000318   0.809161   \n",
       "3               -2.406592  -1.304380  -0.387672 -0.000283   0.800571   \n",
       "4               -2.406592  -1.303866  -0.385148 -0.000300   0.809758   \n",
       "...                   ...        ...        ...       ...        ...   \n",
       "331604          -0.792335   0.908009  -0.323330  0.028591   0.327876   \n",
       "331605          -0.792335   0.893192  -0.316391  0.030232   0.305088   \n",
       "331606          -0.792335   0.878326  -0.310083  0.031854   0.294231   \n",
       "331607          -0.792335   0.843019  -0.294943  0.035285   0.256172   \n",
       "331608           1.410238  -1.271836  -0.351716  0.005918   0.815007   \n",
       "\n",
       "         [C_RHO]  ...  [P_DELTA]  [P_GAMMA]  [P_VEGA]  [P_THETA]   [P_RHO]  \\\n",
       "0      -0.307878  ...   1.120791  -0.013192  0.001135   0.086874  0.592295   \n",
       "1      -0.308329  ...  -1.331602  -0.013434  0.001098   0.090668  0.592878   \n",
       "2      -0.308903  ...  -1.331602  -0.013434  0.001098   0.090668  0.592878   \n",
       "3      -0.308799  ...  -1.331602  -0.013434  0.001098   0.090668  0.592878   \n",
       "4      -0.308329  ...  -1.331602  -0.013434  0.001098   0.090668  0.592878   \n",
       "...          ...  ...        ...        ...       ...        ...       ...   \n",
       "331604  1.567932  ...   0.940700  -0.011274  0.027561   0.073490 -0.464073   \n",
       "331605  1.583821  ...   0.922980  -0.011194  0.029314   0.072979 -0.552965   \n",
       "331606  1.598922  ...   0.905580  -0.010968  0.031117   0.071872 -0.645241   \n",
       "331607  1.624471  ...   0.868226  -0.010533  0.034955   0.070434 -0.859345   \n",
       "331608 -0.276616  ...  -1.245557  -0.007327  0.009872   0.086136 -0.161231   \n",
       "\n",
       "          [P_IV]  [P_VOLUME]   [P_BID]   [P_ASK]   Adj Close  \n",
       "0       3.380989   -0.100406 -0.563368 -0.566211  375.118713  \n",
       "1      -1.037447   -0.099559 -0.005324  0.011661  375.118713  \n",
       "2      -1.037447   -0.099728 -0.022073 -0.007267  375.118713  \n",
       "3      -1.037447   -0.090071 -0.043390 -0.026195  375.118713  \n",
       "4      -1.037447   -0.098712 -0.060139 -0.045123  375.118713  \n",
       "...          ...         ...       ...       ...         ...  \n",
       "331604  0.053898   -0.100406 -0.487046 -0.488228  475.309998  \n",
       "331605  0.038197   -0.099728 -0.480575 -0.481792  475.309998  \n",
       "331606  0.018808   -0.100067 -0.473152 -0.475167  475.309998  \n",
       "331607 -0.016721   -0.100236 -0.462113 -0.453968  475.309998  \n",
       "331608 -0.182059   -0.100406  1.539002  1.591013  475.309998  \n",
       "\n",
       "[331609 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence creation\n",
    "def seq(data, seq_length):\n",
    "    xseq = []\n",
    "    yseq = []\n",
    "    for i in range(len(data)-seq_length-1):\n",
    "        x = data[i:(i+seq_length)]\n",
    "        y = data[i+seq_length]\n",
    "        xseq.append(x)\n",
    "        yseq.append(y)\n",
    "    return np.array(xseq), np.array(yseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ds_new[['[QUOTE_UNIXTIME]', '[EXPIRE_UNIX]', '[STRIKE]', '[UNDERLYING_LAST]', '[C_DELTA]', '[C_GAMMA]', '[C_VEGA]',\n",
    "       '[C_THETA]', '[C_RHO]', '[C_IV]', '[C_VOLUME]','[C_BID]', '[C_ASK]', '[P_DELTA]', '[P_GAMMA]', '[P_VEGA]', '[P_THETA]',\n",
    "       '[P_RHO]', '[P_IV]', '[P_VOLUME]', '[P_BID]', '[P_ASK]']].values\n",
    "target=ds_new[\"Adj Close\"]\n",
    "seq_length = 10 # Number of days to look back\n",
    "X,y = seq(features, seq_length)\n",
    "y = y[:,np.newaxis] # This is to reshape y to be a 2D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "\n",
    "# Then, split the training + validation into separate training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.1765, random_state=42)  # 0.1765 is roughly 15% of the original dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([232110, 10, 22]) torch.Size([232110, 1, 22]) torch.Size([49748, 10, 22]) torch.Size([49748, 1, 22]) torch.Size([49740, 10, 22]) torch.Size([49740, 1, 22])\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype(float)  # Convert to float if it's a numpy array\n",
    "X_train = torch.tensor(X_train, dtype=torch.float)  # Then convert to a PyTorch tensor\n",
    "y_train = torch.tensor(y_train, dtype=torch.float)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float)\n",
    "y_val = torch.tensor(y_val, dtype=torch.float)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float)\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.squeeze(1)  # Removes the unnecessary middle dimension\n",
    "y_val = y_val.squeeze(1)\n",
    "y_test = y_test.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shapes: torch.Size([232110, 10, 22]) torch.Size([232110, 22])\n",
      "Validation shapes: torch.Size([49748, 10, 22]) torch.Size([49748, 22])\n",
      "Test shapes: torch.Size([49740, 10, 22]) torch.Size([49740, 22])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train shapes:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation shapes:\", X_val.shape, y_val.shape)\n",
    "print(\"Test shapes:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size=22,dropout=0.5):\n",
    "        super(RNN_2, self).__init__()\n",
    "        # hidden layer size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True,dropout=dropout)\n",
    "        # self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        test_h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        print(f\"test_h0 has shape,{test_h0.shape}\")  # Should work without error and print the shape)\n",
    "        # initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        # initialize cell state with zeros\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        output, _ = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "        output = self.fc(output[:, -1, :])\n",
    "        return output\n",
    "    \n",
    "# Model instantiation\n",
    "model = RNN_2(input_size=X_train.shape[2], hidden_size=50, num_layers=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_h0 has shape,torch.Size([3, 232110, 50])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "Epoch [10/100], Loss: 0.990469753742218, Val Loss: 0.8920930624008179\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "Epoch [20/100], Loss: 0.9165588617324829, Val Loss: 0.8106120824813843\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "Epoch [30/100], Loss: 0.8630980253219604, Val Loss: 0.7582429647445679\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "Epoch [40/100], Loss: 0.7908488512039185, Val Loss: 0.6835111379623413\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "Epoch [50/100], Loss: 0.7352829575538635, Val Loss: 0.6296195387840271\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "Epoch [60/100], Loss: 0.6997448205947876, Val Loss: 0.5925346612930298\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "Epoch [70/100], Loss: 0.6702725291252136, Val Loss: 0.5600671172142029\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "Epoch [80/100], Loss: 0.6471579670906067, Val Loss: 0.5356026887893677\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "Epoch [90/100], Loss: 0.6300562620162964, Val Loss: 0.5166893005371094\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "test_h0 has shape,torch.Size([3, 232110, 50])\n",
      "test_h0 has shape,torch.Size([3, 49748, 50])\n",
      "Epoch [100/100], Loss: 0.6150023937225342, Val Loss: 0.5012553334236145\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# For early stopping\n",
    "patience = 20\n",
    "optimal_val_loss = np.inf\n",
    "current_patience = 0\n",
    "# Training phase\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    # print(outputs.shape)\n",
    "    # print(y_train.shape)\n",
    "\n",
    "    loss = criterion(outputs, y_train)\n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val)\n",
    "        val_loss = criterion(val_outputs, y_val)\n",
    "        # Early stopping\n",
    "        if val_loss < optimal_val_loss:\n",
    "            optimal_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pt')\n",
    "            current_patience = 0\n",
    "        else:\n",
    "            current_patience += 1\n",
    "            if current_patience == patience:\n",
    "                print(f'Early stopping at epoch {epoch+1}')\n",
    "                # load best model\n",
    "                model.load_state_dict(torch.load('best_model.pt'))\n",
    "                break\n",
    "    \n",
    "    \n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}, Val Loss: {val_loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_h0 has shape,torch.Size([3, 49740, 50])\n",
      "Test Loss: 0.6241307854652405\n",
      "MSE Loss: 0.6241307854652405\n",
      "R2 Score: 0.441430819532\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test)\n",
    "    test_loss = criterion(predictions, y_test)\n",
    "    print(f'Test Loss: {test_loss.item()}')\n",
    "criterion = torch.nn.MSELoss()\n",
    "mse_loss = criterion(predictions, y_test)\n",
    "print(f\"MSE Loss: {mse_loss.item()}\")\n",
    "# R2 score\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(f\"R2 Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YichenWang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
