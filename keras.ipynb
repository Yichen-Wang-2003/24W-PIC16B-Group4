{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = \"tensorflow\"  # actually tensorflow is the default backend. \n",
    "\n",
    "from keras import utils\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import layers\n",
    "from random import randint\n",
    "import sqlite3\n",
    "import math\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('df_2023_h1_feature',), ('df_2023_h1_target',)]\n"
     ]
    }
   ],
   "source": [
    "# Read in the data from the database\n",
    "conn = sqlite3.connect('data/tables.db')\n",
    "# show database content\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "print(cursor.fetchall())\n",
    "# Extract two tables from it and store them in two pd df\n",
    "ds = pd.read_sql_query(\"SELECT * from df_2023_h1_feature\", conn)\n",
    "target = pd.read_sql_query(\"SELECT * from df_2023_h1_target\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>[QUOTE_UNIXTIME]</th>\n",
       "      <th>[EXPIRE_UNIX]</th>\n",
       "      <th>[STRIKE]</th>\n",
       "      <th>[UNDERLYING_LAST]</th>\n",
       "      <th>[C_DELTA]</th>\n",
       "      <th>[C_GAMMA]</th>\n",
       "      <th>[C_VEGA]</th>\n",
       "      <th>[C_THETA]</th>\n",
       "      <th>[C_RHO]</th>\n",
       "      <th>[C_IV]</th>\n",
       "      <th>...</th>\n",
       "      <th>[C_ASK]</th>\n",
       "      <th>[P_DELTA]</th>\n",
       "      <th>[P_GAMMA]</th>\n",
       "      <th>[P_VEGA]</th>\n",
       "      <th>[P_THETA]</th>\n",
       "      <th>[P_RHO]</th>\n",
       "      <th>[P_IV]</th>\n",
       "      <th>[P_VOLUME]</th>\n",
       "      <th>[P_BID]</th>\n",
       "      <th>[P_ASK]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.110828</td>\n",
       "      <td>-1.793839</td>\n",
       "      <td>-1.054517</td>\n",
       "      <td>-2.406592</td>\n",
       "      <td>1.054125</td>\n",
       "      <td>-0.052714</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>-0.391189</td>\n",
       "      <td>-0.307878</td>\n",
       "      <td>11.711458</td>\n",
       "      <td>...</td>\n",
       "      <td>0.676304</td>\n",
       "      <td>1.120791</td>\n",
       "      <td>-0.013192</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>0.086874</td>\n",
       "      <td>0.592295</td>\n",
       "      <td>3.380989</td>\n",
       "      <td>-0.100406</td>\n",
       "      <td>-0.563368</td>\n",
       "      <td>-0.566211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.110828</td>\n",
       "      <td>-1.793839</td>\n",
       "      <td>-0.936052</td>\n",
       "      <td>-2.406592</td>\n",
       "      <td>1.041020</td>\n",
       "      <td>0.036229</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>-0.390353</td>\n",
       "      <td>-0.308470</td>\n",
       "      <td>10.342762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.479078</td>\n",
       "      <td>1.120350</td>\n",
       "      <td>-0.013031</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>0.086843</td>\n",
       "      <td>0.592878</td>\n",
       "      <td>2.599981</td>\n",
       "      <td>-0.100406</td>\n",
       "      <td>-0.563368</td>\n",
       "      <td>-0.566211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.110828</td>\n",
       "      <td>-1.793839</td>\n",
       "      <td>-0.888665</td>\n",
       "      <td>-2.406592</td>\n",
       "      <td>1.035470</td>\n",
       "      <td>0.083539</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>-0.393217</td>\n",
       "      <td>-0.308536</td>\n",
       "      <td>9.795964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400187</td>\n",
       "      <td>1.119196</td>\n",
       "      <td>-0.013111</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>0.086442</td>\n",
       "      <td>0.592606</td>\n",
       "      <td>2.292638</td>\n",
       "      <td>-0.100406</td>\n",
       "      <td>-0.563368</td>\n",
       "      <td>-0.566211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.110828</td>\n",
       "      <td>-1.793839</td>\n",
       "      <td>-0.876819</td>\n",
       "      <td>-2.406592</td>\n",
       "      <td>1.048893</td>\n",
       "      <td>0.103725</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.031159</td>\n",
       "      <td>-0.308217</td>\n",
       "      <td>9.553426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.389734</td>\n",
       "      <td>1.120644</td>\n",
       "      <td>-0.013015</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>0.086741</td>\n",
       "      <td>0.591011</td>\n",
       "      <td>2.214716</td>\n",
       "      <td>-0.100406</td>\n",
       "      <td>-0.563368</td>\n",
       "      <td>-0.566211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.110828</td>\n",
       "      <td>-1.793839</td>\n",
       "      <td>-0.864972</td>\n",
       "      <td>-2.406592</td>\n",
       "      <td>1.030873</td>\n",
       "      <td>0.108141</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>-0.438792</td>\n",
       "      <td>-0.308574</td>\n",
       "      <td>9.529689</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371195</td>\n",
       "      <td>1.119712</td>\n",
       "      <td>-0.013079</td>\n",
       "      <td>0.001120</td>\n",
       "      <td>0.086482</td>\n",
       "      <td>0.591167</td>\n",
       "      <td>2.139460</td>\n",
       "      <td>-0.100406</td>\n",
       "      <td>-0.563368</td>\n",
       "      <td>-0.566211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2.048403</td>\n",
       "      <td>1.811747</td>\n",
       "      <td>-0.343722</td>\n",
       "      <td>-1.301177</td>\n",
       "      <td>1.087280</td>\n",
       "      <td>-0.122734</td>\n",
       "      <td>0.001361</td>\n",
       "      <td>-0.016445</td>\n",
       "      <td>-0.218414</td>\n",
       "      <td>-0.320257</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.277681</td>\n",
       "      <td>1.029739</td>\n",
       "      <td>-0.003202</td>\n",
       "      <td>0.003798</td>\n",
       "      <td>0.051937</td>\n",
       "      <td>0.579229</td>\n",
       "      <td>-0.302191</td>\n",
       "      <td>0.474294</td>\n",
       "      <td>-0.559752</td>\n",
       "      <td>-0.562615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>2.048403</td>\n",
       "      <td>1.811747</td>\n",
       "      <td>-0.331876</td>\n",
       "      <td>-1.301177</td>\n",
       "      <td>0.993170</td>\n",
       "      <td>0.128327</td>\n",
       "      <td>0.003633</td>\n",
       "      <td>-0.658437</td>\n",
       "      <td>-0.221646</td>\n",
       "      <td>-0.193897</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.295629</td>\n",
       "      <td>1.017321</td>\n",
       "      <td>-0.001768</td>\n",
       "      <td>0.004134</td>\n",
       "      <td>0.047664</td>\n",
       "      <td>0.573902</td>\n",
       "      <td>-0.312379</td>\n",
       "      <td>-0.081430</td>\n",
       "      <td>-0.559181</td>\n",
       "      <td>-0.562047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2.048403</td>\n",
       "      <td>1.811747</td>\n",
       "      <td>-0.320029</td>\n",
       "      <td>-1.301177</td>\n",
       "      <td>1.114005</td>\n",
       "      <td>-0.221770</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.166811</td>\n",
       "      <td>-0.217014</td>\n",
       "      <td>-0.426917</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326988</td>\n",
       "      <td>1.004559</td>\n",
       "      <td>-0.000511</td>\n",
       "      <td>0.004453</td>\n",
       "      <td>0.043650</td>\n",
       "      <td>0.574213</td>\n",
       "      <td>-0.322530</td>\n",
       "      <td>-0.039751</td>\n",
       "      <td>-0.558610</td>\n",
       "      <td>-0.561479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2.048403</td>\n",
       "      <td>1.811747</td>\n",
       "      <td>-0.308183</td>\n",
       "      <td>-1.301177</td>\n",
       "      <td>1.091706</td>\n",
       "      <td>-0.095609</td>\n",
       "      <td>0.001270</td>\n",
       "      <td>0.041419</td>\n",
       "      <td>-0.217512</td>\n",
       "      <td>-0.396257</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.345922</td>\n",
       "      <td>0.985784</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.004826</td>\n",
       "      <td>0.038733</td>\n",
       "      <td>0.569858</td>\n",
       "      <td>-0.332206</td>\n",
       "      <td>-0.075330</td>\n",
       "      <td>-0.557848</td>\n",
       "      <td>-0.560722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2.048403</td>\n",
       "      <td>1.811747</td>\n",
       "      <td>-0.296336</td>\n",
       "      <td>-1.301177</td>\n",
       "      <td>1.030066</td>\n",
       "      <td>0.135896</td>\n",
       "      <td>0.002822</td>\n",
       "      <td>-0.297890</td>\n",
       "      <td>-0.219804</td>\n",
       "      <td>-0.332400</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.362489</td>\n",
       "      <td>0.965414</td>\n",
       "      <td>0.003147</td>\n",
       "      <td>0.005264</td>\n",
       "      <td>0.032936</td>\n",
       "      <td>0.567874</td>\n",
       "      <td>-0.338596</td>\n",
       "      <td>0.042761</td>\n",
       "      <td>-0.556897</td>\n",
       "      <td>-0.559776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      [QUOTE_UNIXTIME]  [EXPIRE_UNIX]  [STRIKE]  [UNDERLYING_LAST]  [C_DELTA]  \\\n",
       "0            -1.110828      -1.793839 -1.054517          -2.406592   1.054125   \n",
       "1            -1.110828      -1.793839 -0.936052          -2.406592   1.041020   \n",
       "2            -1.110828      -1.793839 -0.888665          -2.406592   1.035470   \n",
       "3            -1.110828      -1.793839 -0.876819          -2.406592   1.048893   \n",
       "4            -1.110828      -1.793839 -0.864972          -2.406592   1.030873   \n",
       "...                ...            ...       ...                ...        ...   \n",
       "9995          2.048403       1.811747 -0.343722          -1.301177   1.087280   \n",
       "9996          2.048403       1.811747 -0.331876          -1.301177   0.993170   \n",
       "9997          2.048403       1.811747 -0.320029          -1.301177   1.114005   \n",
       "9998          2.048403       1.811747 -0.308183          -1.301177   1.091706   \n",
       "9999          2.048403       1.811747 -0.296336          -1.301177   1.030066   \n",
       "\n",
       "      [C_GAMMA]  [C_VEGA]  [C_THETA]   [C_RHO]     [C_IV]  ...   [C_ASK]  \\\n",
       "0     -0.052714  0.000146  -0.391189 -0.307878  11.711458  ...  0.676304   \n",
       "1      0.036229  0.000190  -0.390353 -0.308470  10.342762  ...  0.479078   \n",
       "2      0.083539  0.000199  -0.393217 -0.308536   9.795964  ...  0.400187   \n",
       "3      0.103725  0.000140   0.031159 -0.308217   9.553426  ...  0.389734   \n",
       "4      0.108141  0.000225  -0.438792 -0.308574   9.529689  ...  0.371195   \n",
       "...         ...       ...        ...       ...        ...  ...       ...   \n",
       "9995  -0.122734  0.001361  -0.016445 -0.218414  -0.320257  ... -0.277681   \n",
       "9996   0.128327  0.003633  -0.658437 -0.221646  -0.193897  ... -0.295629   \n",
       "9997  -0.221770  0.000563   0.166811 -0.217014  -0.426917  ... -0.326988   \n",
       "9998  -0.095609  0.001270   0.041419 -0.217512  -0.396257  ... -0.345922   \n",
       "9999   0.135896  0.002822  -0.297890 -0.219804  -0.332400  ... -0.362489   \n",
       "\n",
       "      [P_DELTA]  [P_GAMMA]  [P_VEGA]  [P_THETA]   [P_RHO]    [P_IV]  \\\n",
       "0      1.120791  -0.013192  0.001135   0.086874  0.592295  3.380989   \n",
       "1      1.120350  -0.013031  0.001152   0.086843  0.592878  2.599981   \n",
       "2      1.119196  -0.013111  0.001152   0.086442  0.592606  2.292638   \n",
       "3      1.120644  -0.013015  0.001157   0.086741  0.591011  2.214716   \n",
       "4      1.119712  -0.013079  0.001120   0.086482  0.591167  2.139460   \n",
       "...         ...        ...       ...        ...       ...       ...   \n",
       "9995   1.029739  -0.003202  0.003798   0.051937  0.579229 -0.302191   \n",
       "9996   1.017321  -0.001768  0.004134   0.047664  0.573902 -0.312379   \n",
       "9997   1.004559  -0.000511  0.004453   0.043650  0.574213 -0.322530   \n",
       "9998   0.985784   0.001149  0.004826   0.038733  0.569858 -0.332206   \n",
       "9999   0.965414   0.003147  0.005264   0.032936  0.567874 -0.338596   \n",
       "\n",
       "      [P_VOLUME]   [P_BID]   [P_ASK]  \n",
       "0      -0.100406 -0.563368 -0.566211  \n",
       "1      -0.100406 -0.563368 -0.566211  \n",
       "2      -0.100406 -0.563368 -0.566211  \n",
       "3      -0.100406 -0.563368 -0.566211  \n",
       "4      -0.100406 -0.563368 -0.566211  \n",
       "...          ...       ...       ...  \n",
       "9995    0.474294 -0.559752 -0.562615  \n",
       "9996   -0.081430 -0.559181 -0.562047  \n",
       "9997   -0.039751 -0.558610 -0.561479  \n",
       "9998   -0.075330 -0.557848 -0.560722  \n",
       "9999    0.042761 -0.556897 -0.559776  \n",
       "\n",
       "[10000 rows x 22 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# custom train test val split\n",
    "\n",
    "X_train = ds[0:10000]\n",
    "y_train = target[0:10000]\n",
    "X_val = ds[10001:11001]\n",
    "y_val = target[10001:11001]\n",
    "X_test = ds[11002: 12002]\n",
    "y_test = target[11002: 12002]\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = X_train.join(y_train)\n",
    "val_data = X_val.join(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataloader for train,val,test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_input = keras.Input(\n",
    "    shape = (ds_new.iloc[0].shape),\n",
    "    name = \"features\",\n",
    "    dtype = \"float64\"\n",
    ")\n",
    "features = layers.conv1D(22, activation='relu')(features_input)\n",
    "features = layers.conv1D(22, activation='relu')(features_input)\n",
    "features = layers.Dense(22, activation='relu')(features)\n",
    "output = layers.Dense(1)(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " features (InputLayer)       [(None, 22)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                736       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 769 (3.00 KB)\n",
      "Trainable params: 769 (3.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "simple_option_model = keras.Model(\n",
    "    inputs = features_input,\n",
    "    outputs = output\n",
    ")\n",
    "simple_option_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/Users/xipengdu/anaconda3/envs/PIC16B-24W/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/xipengdu/anaconda3/envs/PIC16B-24W/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/xipengdu/anaconda3/envs/PIC16B-24W/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/xipengdu/anaconda3/envs/PIC16B-24W/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/xipengdu/anaconda3/envs/PIC16B-24W/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/Users/xipengdu/anaconda3/envs/PIC16B-24W/lib/python3.11/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/xipengdu/anaconda3/envs/PIC16B-24W/lib/python3.11/site-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/Users/xipengdu/anaconda3/envs/PIC16B-24W/lib/python3.11/site-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/xipengdu/anaconda3/envs/PIC16B-24W/lib/python3.11/site-packages/keras/src/losses.py\", line 361, in __init__  **\n        super().__init__(mean_squared_error, name=name, reduction=reduction)\n    File \"/Users/xipengdu/anaconda3/envs/PIC16B-24W/lib/python3.11/site-packages/keras/src/losses.py\", line 248, in __init__\n        super().__init__(reduction=reduction, name=name)\n    File \"/Users/xipengdu/anaconda3/envs/PIC16B-24W/lib/python3.11/site-packages/keras/src/losses.py\", line 84, in __init__\n        losses_utils.ReductionV2.validate(reduction)\n    File \"/Users/xipengdu/anaconda3/envs/PIC16B-24W/lib/python3.11/site-packages/keras/src/utils/losses_utils.py\", line 87, in validate\n        if key not in cls.all():\n\n    TypeError: Expected float32 passed to parameter 'y' of op 'Equal', got 'auto' of type 'str' instead. Error: Expected float32, but got auto of type 'str'.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m simple_option_model\u001b[38;5;241m.\u001b[39mcompile(optimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      2\u001b[0m               loss \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mMeanSquaredError,\n\u001b[1;32m      3\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m )\n\u001b[0;32m----> 5\u001b[0m \u001b[43msimple_option_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_new\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/PIC16B-24W/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/lc/cr1vnr593_l4t1814jghhy980000gn/T/__autograph_generated_filepxydpvow.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/Users/xipengdu/anaconda3/envs/PIC16B-24W/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/xipengdu/anaconda3/envs/PIC16B-24W/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/xipengdu/anaconda3/envs/PIC16B-24W/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/xipengdu/anaconda3/envs/PIC16B-24W/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/xipengdu/anaconda3/envs/PIC16B-24W/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/Users/xipengdu/anaconda3/envs/PIC16B-24W/lib/python3.11/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/xipengdu/anaconda3/envs/PIC16B-24W/lib/python3.11/site-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/Users/xipengdu/anaconda3/envs/PIC16B-24W/lib/python3.11/site-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/xipengdu/anaconda3/envs/PIC16B-24W/lib/python3.11/site-packages/keras/src/losses.py\", line 361, in __init__  **\n        super().__init__(mean_squared_error, name=name, reduction=reduction)\n    File \"/Users/xipengdu/anaconda3/envs/PIC16B-24W/lib/python3.11/site-packages/keras/src/losses.py\", line 248, in __init__\n        super().__init__(reduction=reduction, name=name)\n    File \"/Users/xipengdu/anaconda3/envs/PIC16B-24W/lib/python3.11/site-packages/keras/src/losses.py\", line 84, in __init__\n        losses_utils.ReductionV2.validate(reduction)\n    File \"/Users/xipengdu/anaconda3/envs/PIC16B-24W/lib/python3.11/site-packages/keras/src/utils/losses_utils.py\", line 87, in validate\n        if key not in cls.all():\n\n    TypeError: Expected float32 passed to parameter 'y' of op 'Equal', got 'auto' of type 'str' instead. Error: Expected float32, but got auto of type 'str'.\n"
     ]
    }
   ],
   "source": [
    "simple_option_model.compile(optimizer = \"adam\",\n",
    "              loss = keras.losses.MeanSquaredError,\n",
    "              metrics=['accuracy']\n",
    ")\n",
    "simple_option_model.fit(ds_new, target_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PIC16B-24W",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
