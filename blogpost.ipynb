{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Option Pricing with Neuron Network\"\n",
    "author: \"Xipeng Du\"\n",
    "date: \"2024-03-13\"\n",
    "categories: [option pricing, project]\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Introduction: Basic Idea of Option Pricing\n",
    "\n",
    "Option is a financial contract that give the buyer the right to buy or sell certain quantity of assets as specific strike price on or before maturity date, and the buyer needs to pay premium or \"option price\" in this context to the seller of this contract. Option pricing is a way to evaluate the fair value of an option which corresponds to its striking price, maturity time and risk involved with the stock. Traditionally, traders use models like Black-Scholes model to estimate the price of an option, but these models have their limitations and base assumptions that are not certainly sound. With the power of machine learning, we are deriving a model that will evaluate the fair value of an option based on current stock price, quality, greeks of the stock, implied volatility of the stock. We will utilize pytorch to deploy a machine learning model to fit from past option price data for the S&P 500 index. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Data Acquisition\n",
    "\n",
    "For the first step of our project is acquiring the data. We found a dataset [link] on kaggle, and traced to the source which is optiondx[link]. This websites contains a text based datasets with end of date data for free. The following is the features. Then, realizing we might need real time stock price data for target, we utilize a package called yfinance which calls yahoo finance's unofficial api to download data from a time range by `yf.download` function, which gets us an adjusted closed data at the end of each trading date. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# getting stock prices for target evaluation\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "target = pd.DataFrame(yf.download(['SPY'], start=\"2023-06-01\", end=\"2023-12-31\")['Adj Close'])\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# importing neccessary packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sqlite3\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Read in the data from Jan 2023 to May 2023\n",
    "df_2023_h1 = pd.DataFrame()\n",
    "for i in [202301, 202302, 202303, 202304,  202305]:\n",
    "    df_2023_h1 = pd.concat([df_2023_h1, pd.read_table(f'data/spy_eod_{i}.txt', sep=',')], ignore_index=True)\n",
    "df_2023_h1.columns = df_2023_h1.columns.str.strip()\n",
    "\n",
    "# also drop expiration date later than 2024\n",
    "df_2023_h1 = df_2023_h1[df_2023_h1['[EXPIRE_DATE]'] <= ' 2023-12-31']\n",
    "df_2023_h1 = df_2023_h1[df_2023_h1['[EXPIRE_DATE]'] >= ' 2023-06-01']\n",
    "df_2023_h1 = df_2023_h1.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We strip away all the spaces of the column names in this step for easier access, and removed the entries that target cannot be calculated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# change the string dates to datetime64\n",
    "df_2023_h1['[QUOTE_DATE]'] = df_2023_h1['[QUOTE_DATE]'].apply(np.datetime64)\n",
    "df_2023_h1['[EXPIRE_DATE]'] = df_2023_h1['[EXPIRE_DATE]'].apply(np.datetime64)\n",
    "\n",
    "# merge our adj close stock data on EXPIRE_DATE\n",
    "target['[EXPIRE_DATE]'] = target.index\n",
    "target['[EXPIRE_DATE]'].astype('datetime64[ns]')\n",
    "\n",
    "df_2023_h1 = pd.merge(df_2023_h1, target, on = '[EXPIRE_DATE]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Setting targets\n",
    "\n",
    "Then, we have to set a target for our machine learning model. We first utilized a naive estimation of the option price, then start to focus on the intrinsic value of call option. with price = (K - S). \n",
    "<br>\n",
    "Later, we set our target as intrinsic value of price based on payoff of call and put options, based on the function of discounted price = (K - S) * e^(-rt) where r is a risk free investment rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Add new cols for the target, namely -rt and price diff\n",
    "df_2023_h1['-rt'] = -0.04*(df_2023_h1['[EXPIRE_UNIX]'] - df_2023_h1['[QUOTE_UNIXTIME]'])/(3600*365*24)\n",
    "df_2023_h1['price_diff'] = df_2023_h1['[STRIKE]'] - df_2023_h1['Adj Close']\n",
    "df_2023_h1['-rt'] = pd.to_numeric(df_2023_h1['-rt'])\n",
    "df_2023_h1['exp(-rt)'] = df_2023_h1['-rt'].apply(lambda x: math.exp(x))\n",
    "df_2023_h1 = df_2023_h1.loc[:, ~df_2023_h1.columns.str.contains('^Unnamed')]   \n",
    "df_2023_h1['discounted_price'] = df_2023_h1['price_diff'] * df_2023_h1['exp(-rt)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We normalize all numerical columns with a standard scaler. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df_2023_h1 = df_2023_h1[['[EXPIRE_UNIX]', '[QUOTE_DATE]', '[EXPIRE_DATE]', '[STRIKE]', '[UNDERLYING_LAST]', '[C_DELTA]', '[C_GAMMA]', '[C_VEGA]',\n",
    "       '[C_THETA]', '[C_RHO]', '[C_IV]', '[C_VOLUME]','[C_BID]', '[C_ASK]', '[P_DELTA]', '[P_GAMMA]', '[P_VEGA]', '[P_THETA]',\n",
    "       '[P_RHO]', '[P_IV]', '[P_VOLUME]', '[P_BID]', '[P_ASK]', 'Adj Close']]\n",
    "\n",
    "df_2023_h1 = df_2023_h1.replace(r'^\\s*$', 0, regex=True)\n",
    "\n",
    "# Basic normalization and standardization\n",
    "# run block of code and catch warnings\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "with warnings.catch_warnings():\n",
    "\t# ignore all caught warnings\n",
    "\twarnings.filterwarnings(\"ignore\")\n",
    "\t# execute code that will generate warnings\n",
    "\tnumeric_cols = ['[QUOTE_UNIX]', '[EXPIRE_UNIX]', '[STRIKE]', '[UNDERLYING_LAST]', '[C_DELTA]', '[C_GAMMA]', '[C_VEGA]',\n",
    "       '[C_THETA]', '[C_RHO]', '[C_IV]', '[C_VOLUME]','[C_BID]', '[C_ASK]', '[P_DELTA]', '[P_GAMMA]', '[P_VEGA]', '[P_THETA]',\n",
    "       '[P_RHO]', '[P_IV]', '[P_VOLUME]', '[P_BID]', '[P_ASK]']  # not sure about all this\n",
    "\tscaler = StandardScaler()\n",
    "\tdf_2023_h1[numeric_cols] = scaler.fit_transform(df_2023_h1[numeric_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Data Structures\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Baseline model: Linear Regression\n",
    "\n",
    "We need to set a target for the neuron network to beat, if any model cannot beat a linear approximation of stock market in the long run it is a failure. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Autogluon Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Neuron Network Attempt 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Neuron Network Attempt 2\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
